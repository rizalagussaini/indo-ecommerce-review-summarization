{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indonesian E-commerce Review Summarization with Mistral-7B-Instruct\n",
    "\n",
    "This notebook demonstrates how to use Mistral-7B-Instruct for abstractive summarization of Indonesian e-commerce reviews.\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, install the required dependencies if you haven't already:\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from indo_ecommerce_review_summarization.preprocessing import clean_text, normalize_text\n",
    "from indo_ecommerce_review_summarization.models import create_summarization_prompt, load_model\n",
    "from indo_ecommerce_review_summarization.evaluation import calculate_rouge\n",
    "\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model\n",
    "\n",
    "Load Mistral-7B-Instruct model. You can use quantization to reduce memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model - use 4-bit quantization to save memory\n",
    "model = load_model(\n",
    "    model_name=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    model_type=\"huggingface\",\n",
    "    load_in_4bit=True,\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Single Review Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Indonesian e-commerce review\n",
    "review = \"\"\"\n",
    "Barang udah sampai dgn selamat. Packaging rapi bgt, bubble wrap tebal jd gak khawatir pecah. \n",
    "Kualitas produk oke, sesuai deskripsi. Harga agak mahal tp worth it sih. \n",
    "Pengiriman cepet bgt cuma 2 hari sampe. Seller responsif, fast respon banget. \n",
    "Puas bgt sama pembelian kali ini. Recommended seller! üëç\n",
    "\"\"\"\n",
    "\n",
    "# Preprocess the review\n",
    "cleaned_review = clean_text(review)\n",
    "print(\"Cleaned review:\")\n",
    "print(cleaned_review)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Create prompt\n",
    "prompt = create_summarization_prompt(\n",
    "    reviews=[cleaned_review],\n",
    "    model_type=\"mistral\",\n",
    "    max_length=50\n",
    ")\n",
    "\n",
    "print(\"Prompt:\")\n",
    "print(prompt)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Generate summary\n",
    "summary = model.generate(\n",
    "    prompt,\n",
    "    max_new_tokens=128,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9\n",
    ")\n",
    "\n",
    "print(\"Generated Summary:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Multiple Reviews Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple reviews\n",
    "reviews = [\n",
    "    \"Produk bagus banget, sesuai ekspektasi. Pengiriman cepat.\",\n",
    "    \"Kualitas oke, tapi pengiriman agak lama. Overall puas sih.\",\n",
    "    \"Barang mantap! Seller ramah dan fast respon. Recommended!\",\n",
    "    \"Harga sebanding dengan kualitas. Packing rapi. Good job!\"\n",
    "]\n",
    "\n",
    "# Create prompt for multiple reviews\n",
    "prompt = create_summarization_prompt(\n",
    "    reviews=reviews,\n",
    "    model_type=\"mistral\"\n",
    ")\n",
    "\n",
    "# Generate summary\n",
    "summary = model.generate(\n",
    "    prompt,\n",
    "    max_new_tokens=150,\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "print(\"Summary of multiple reviews:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Evaluation with ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: evaluate against reference summary\n",
    "reference_summary = \"Produk berkualitas dengan pengiriman cepat dan seller yang responsif.\"\n",
    "predicted_summary = summary  # Use the generated summary from above\n",
    "\n",
    "# Calculate ROUGE scores\n",
    "scores = calculate_rouge(\n",
    "    predictions=predicted_summary,\n",
    "    references=reference_summary\n",
    ")\n",
    "\n",
    "print(\"ROUGE Scores:\")\n",
    "for metric, values in scores.items():\n",
    "    print(f\"\\n{metric.upper()}:\")\n",
    "    for key, value in values.items():\n",
    "        print(f\"  {key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple reviews to summarize\n",
    "reviews_list = [\n",
    "    [\"Barang bagus, pengiriman cepat, seller ramah.\"],\n",
    "    [\"Produk sesuai deskripsi, packing aman.\"],\n",
    "    [\"Kualitas oke, harga terjangkau. Recommended!\"]\n",
    "]\n",
    "\n",
    "# Create prompts for all reviews\n",
    "prompts = [create_summarization_prompt(reviews, model_type=\"mistral\") for reviews in reviews_list]\n",
    "\n",
    "# Generate summaries in batch\n",
    "summaries = model.batch_generate(\n",
    "    prompts,\n",
    "    max_new_tokens=100,\n",
    "    temperature=0.7,\n",
    "    batch_size=2\n",
    ")\n",
    "\n",
    "# Display results\n",
    "for i, (review, summary) in enumerate(zip(reviews_list, summaries), 1):\n",
    "    print(f\"\\nReview {i}: {review[0]}\")\n",
    "    print(f\"Summary: {summary}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. Loading and using Mistral-7B-Instruct for Indonesian review summarization\n",
    "2. Text preprocessing for Indonesian e-commerce reviews\n",
    "3. Single and multiple review summarization\n",
    "4. Evaluation using ROUGE metrics\n",
    "5. Batch processing for efficiency\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Experiment with different prompt templates\n",
    "- Try aspect-based summarization\n",
    "- Fine-tune the model on your specific dataset\n",
    "- Compare with other models (LLaMA, GPT, etc.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
